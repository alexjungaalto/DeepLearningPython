{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation functions. Demo.\n",
    "\n",
    "The inputs of the artificial neuron are weighted and summed up in $z = b+w_{1}x_{1}+...+w_{n}x_{n}$.\n",
    "The artificial neuron then applies a non-linear **activation function** to the weighted sum $z$. The output $g(z)$ of a neuron is often referred to as the **activation**. \n",
    "In this demo you can see how activation functions introduce non-linearity into the ANN model. As an example, we will use simple ANN only with a few neurons:\n",
    "\n",
    "<img src=\"actfunc.png\" width=\"600\">\n",
    "\n",
    "The code is stored in 'actfunctions.py' file and function `actfunctions` is loaded from there. The inputs and outputs of this ANN's hidden units are visualized and parameters of the model (weights and biases) can be interactively modified in some range.\\\n",
    "After executing the cell with the function, the window will pop-up and will ask to enter the mode - `actfunc` or `gradient`.\\\n",
    "Type in one of the options, then enter the name of the activation function and start changing model parameters with sliders.\\\n",
    "The `actfunc` is a function, which will plot selected activation function and print some info about it. Interactive plots corresponding to ANN discussed above will be also displayed. Try to change the parameters of the model and see how this will affect the output. Note the differences between activation functions.\\\n",
    "The `gradient` is a function for demonstrating the local gradient of the activation function. Note the differences between gradients of different activation functions and think what consequences this can have for the full gradient of the network and weights updates.\\\n",
    "You can read more about activation functions [here](https://cs231n.github.io/neural-networks-1/#actfun) and watch corresponding [lecture](https://www.youtube.com/watch?v=d14TUNcbn1k&list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv&index=4) from Stanford Computer Vision course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from actfunctions import actfunctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter mode. Valid names are:\n",
      "'actfunc', 'gradient'\n",
      "gradient\n",
      "Enter the name of the activation function. Valid names are:\n",
      "'relu','leakyrelu', 'elu', sigmoid', 'tanh'\n",
      "relu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4cd1c780d1e417e959e53ddcff5e50f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntSlider(value=0, description='$weight \\\\;w$', max=10, min=-10), IntSlider(value=0, descriptioâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cc51894cbde4fa0a058225e425a803e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "actfunctions()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
